{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def tokenize_transcript(transcripts):\n",
    "# \tfor idx, song in enumerate(transcripts):\n",
    "# \t\tlyrics = song[\"lyrics\"]\n",
    "# \t\tlyrics = lyrics.replace(\"\\\\n\", \" \").replace(\"[Hook\", \" \").replace(\"[Verse\", \" \").replace(\"b\", \" \", 1)\n",
    "# \t\ttranscripts[idx][\"lyrics\"] = re.findall(r\"[a-z]+\", lyrics.lower())\n",
    "\n",
    "# \treturn transcripts\n",
    "\n",
    "with open(\"songData.json\", \"r\") as f:\n",
    "\tsong_transcripts = json.load(f)\n",
    "\n",
    "\n",
    "songs = list(song_transcripts.values())\n",
    "# songs = tokenize_transcript(songs)\n",
    "# print(songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75827, 4545)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "songlist = [song[\"lyrics\"] for song in songs]\n",
    "songlist.append(\"hello good morning how are you doing\")\n",
    "lyric_matrix = vectorizer.fit_transform(songlist).transpose()\n",
    "print(lyric_matrix.shape)\n",
    "u, s, v = svds(lyric_matrix, k=100)\n",
    "words_compressed, _, docs_compressed = svds(lyric_matrix, k = 30)\n",
    "docs_compressed = docs_compressed.transpose()\n",
    "\n",
    "\n",
    "word_to_index = vectorizer.vocabulary_\n",
    "\n",
    "index_to_word = {i:t for t,i, in word_to_index.items()}\n",
    "words_compressed = normalize(words_compressed, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(10):\\n\\tprint(songs[i][\"title\"])\\n\\tfor title, score in closest_songs(i):\\n\\t\\tprint(\"{}:{:.3f}\".format(title[:40], score))\\n\\tprint()\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tsne = TSNE(verbose=1)\n",
    "#projected_docs = tsne.fit_transform(docs_compressed)\n",
    "#print(projected_docs.shape)\n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.scatter(projected_docs[:,0], projected_docs[:,1])\n",
    "#plt.show()\n",
    "\n",
    "docs_compressed = normalize(docs_compressed, axis=1)\n",
    "\n",
    "\n",
    "def closest_songs(project_index_in, k=10):\n",
    "\tsims = docs_compressed.dot(docs_compressed[project_index_in,:])\n",
    "\tasort = np.argsort(-sims)[:k+1]\n",
    "\treturn [(songs[i][\"title\"], sims[i]/sims[asort[0]]) for i in asort[1:]]\n",
    "'''\n",
    "for i in range(10):\n",
    "\tprint(songs[i][\"title\"])\n",
    "\tfor title, score in closest_songs(i):\n",
    "\t\tprint(\"{}:{:.3f}\".format(title[:40], score))\n",
    "\tprint()\n",
    "'''   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u\"I'm Good\", 0.8179782958798242), (u'Get Fly', 0.7392305911092958), (u'Good Morning', 0.709221422788607), (u'The Good, The Bad, The Ugly', 0.6967254710598475), (u'Good Enough', 0.6840587253251521), (u'Light Up', 0.672167575056534), (u'Stop Being Greedy', 0.6595125889331699), (u'One Way Trip', 0.6517738820440194), (u'Good Night', 0.6487589886250912), (u'High Rise', 0.641207744225391)]\n"
     ]
    }
   ],
   "source": [
    "print(closest_songs(4544))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e82ec074ee35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Good morning how are you doing today\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0muq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mq_compressed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqs_compressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mqs_compressed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqs_compressed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             raise ValueError(\n\u001b[0;32m--> 860\u001b[0;31m                 \u001b[0;34m\"Iterable over raw text documents expected, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m                 \"string object received.\")\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "query_matrix = vectorizer.fit_transform([\"Good morning how are you doing today\"]).transpose()\n",
    "print(query_matrix.shape)\n",
    "uq, sq, vq = svds(query_matrix, k=1)\n",
    "q_compressed, _, qs_compressed = svds(query_matrix, k = 40)\n",
    "qs_compressed = qs_compressed.transpose()\n",
    "print(qs_compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
